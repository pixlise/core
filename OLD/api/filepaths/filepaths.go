// Licensed to NASA JPL under one or more contributor
// license agreements. See the NOTICE file distributed with
// this work for additional information regarding copyright
// ownership. NASA JPL licenses this file to you under
// the Apache License, Version 2.0 (the "License"); you may
// not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing,
// software distributed under the License is distributed on an
// "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
// KIND, either express or implied.  See the License for the
// specific language governing permissions and limitations
// under the License.

// Defines all paths/file names used in S3 for storage of our data. This allows a more centralised
// view of where our data is in S3 and makes changing storage/paths easier
package filepaths

import (
	"path"
	"strings"

	"github.com/pixlise/core/v3/core/fileaccess"
	"github.com/pixlise/core/v3/core/pixlUser"
)

// This package contains all file paths that the PIXLISE API should ever need to access. All been centralised
// so we have one place to change it all. Several helper functions are provided to make certain paths given
// a user ID or dataset ID, etc.

// Our data resides across several buckets:

////////////////////////////////////////////////////////////////////////////////////
// Data Bucket
////////////////////////////////////////////////////////////////////////////////////
/*
Root directory containing our dataset files
	- Datasets/
	----<dataset-id>/
	--------dataset.bin
	--------Context image files (.png or .jpg)
	--------RGBU multi-spectral files (.tif)
	--------diffraction-db.bin
	--------summary.json
*/
const RootDatasets = "Datasets"

// The dataset file containing all spectra, housekeeping, beam locations, etc. Created by data-converter
const DatasetFileName = "dataset.bin"

// Diffraction peak database, generated by diffraction-detector when dataset is imported
const DiffractionDBFileName = "diffraction-db.bin"

// Contains metadata for the dataset, easily downloadable/browsable. dataset-tile-updater pulls these in to form the datasets.json file
const DatasetSummaryFileName = "summary.json"

func GetDatasetFilePath(datasetID string, fileName string) string {
	return path.Join(RootDatasets, datasetID, fileName)
}

/*
Root directory containing all archived data set zips as we downloaded them
  - Archive/
*/
const RootArchive = "Archive"

/*
Root directory containing dataset summaries (named <datset-id>.json). This makes it easier to list all datasets, rather than listing all files in \Datasets
  - DatasetSummaries/
*/
const RootDatasetSummaries = "DatasetSummaries"

// Get a dataset summary file path given a dataset ID
func GetDatasetSummaryFilePath(datasetID string) string {
	return path.Join(RootDatasetSummaries, datasetID+".json")
}

////////////////////////////////////////////////////////////////////////////////////
// Config Bucket
////////////////////////////////////////////////////////////////////////////////////

/*
Root directory containing all dataset configs
  - DatasetConfig/
  - ----import-times.json - Specifies when each dataset was imported (map id->unix time)
*/
const RootDatasetConfig = "DatasetConfig"

// Dataset last import time path, used by importer
const DatasetLastImportTimesPath = RootDatasetConfig + "/import-times.json"

/*
Root directory containing all detector configs
  - DetectorConfig/
  - ----<config-name>/ - Name shown on UI, eg PIXL or Breadboard
  - --------pixlise-config.json - UI config values for this detector, eg detector energy range, window material, etc
  - --------PiquantConfigs/
  - ------------<version>/ - eg v1, v2, v3
  - ----------------config.json - The PIQUANT config file, used by quant "runner", in docker container. References other files
  - ----------------<other files>.msa or .csv - These are referenced by config.json and passed to PIQUANT exe as parameters
*/
const RootDetectorConfig = "DetectorConfig"

// Piquant configs sub-dir
//   - NOTE: Quant creation doesn't use GetDetectorConfigPath, maybe DetectorConfig is hard-coded into docker container!
//     TODO: remove that
const PiquantConfigSubDir = "PiquantConfigs"

// Get a PIXLISE detector config file path given the config name
func GetDetectorConfigFilePath(configName string) string {
	return path.Join(RootDetectorConfig, configName, "pixlise-config.json")
}

// Get a detector config path (used by PIQUANT) given the config name, version and optionally a file name. If file name is blank
// then the directory path above it is returned
func GetDetectorConfigPath(configName string, version string, fileName string) string {
	if len(version) > 0 {
		if len(fileName) > 0 {
			return path.Join(RootDetectorConfig, configName, PiquantConfigSubDir, version, fileName)
		} else {
			return path.Join(RootDetectorConfig, configName, PiquantConfigSubDir, version)
		}
	}
	return path.Join(RootDetectorConfig, configName, PiquantConfigSubDir)
}

// File name of "overall" piquant config file, which references the individual files PIQUANT will need
const PiquantConfigFileName = "config.json"

/*
Root directory of PIXLISE-specific config files
  - PixliseConfig/
  - ----auth0.pem - Certificate needed by Auth0 to verify a user request is valid
  - ----datasets.json - Dataset list (tiles)
  - ----piquant-version.json - Docker container for running PIQUANT
  - ----bad-dataset-ids.json - Contains a list of Dataset IDs to ignore when generating dataset tiles
*/
const RootPixliseConfigPath = "PixliseConfig"

// Auth0 PEM file which API uses to verify JWTs
const Auth0PemFileName = "auth0.pem"

// Gets dataset list file (which UI shows as tiles).
// NOTE: This is regenerated every time Datasets/ changes by lambda function: dataset-tile-updater
func GetDatasetListPath() string {
	return GetConfigFilePath("datasets.json")
}

func GetDatasetsAuthPath() string {
	return GetConfigFilePath("datasets-auth.json")
}

func GetPublicObjectsPath() string {
	return GetConfigFilePath("public-objects.json")
}

// Config contains the docker container to use for PIQUANT. Separate from config.json because users can configure this in UI
const PiquantVersionFileName = "piquant-version.json"

// Contains a list of Dataset IDs to ignore when generating dataset tiles. This is hand
// maintained, only used when we have a bad dataset is downloaded that will never be usable
// This way we can prevent it from being written to <Config bucket>/PixliseConfig/datasets.json
// Just a work-around for having OCS fetcher put files there without our control. If a bad
// dataset download happens, there's no point in showing a broken tile for it forever!
const BadDatasetIDsFile = "bad-dataset-ids.json"

// Getting a config file path relative to the root of the bucket
func GetConfigFilePath(fileName string) string {
	return path.Join(RootPixliseConfigPath, fileName)
}

////////////////////////////////////////////////////////////////////////////////////
// User Content Bucket
////////////////////////////////////////////////////////////////////////////////////

/*
Root directory for bucket containing all user-created content
  - UserContent/
  - ----<user-id>/
  - --------ElementSets.json - User created element sets
  - --------DataExpressions.json - User created expressions
  - --------RGBMixes.json - User created RGB mixes
  - --------<dataset-id>/
  - ------------ROI.json - User created ROIs
  - ------------Tags.json - Dataset tags
  - ------------SpectrumAnnotation.json
  - ------------multi-quant-z-stack.json - The current z-stack on multi-quant panel
  - ------------Quantifications/
  - ----------------<quant-id>.bin - The combined.csv file converted to protobuf binary format by quant-converter
  - ----------------<quant-id>.csv - Copied from Job Bucket/JobData/<job-id>/output/combined.csv
  - ----------------<quant-id>-logs/ - Copied from Job Bucket/JobData/<job-id>/piquant-logs/
  - ----------------summary-<quant-id>.json - Quant summary file
  - ------------LastPiquantOutput/ - Last output of fit command
  - ------------ViewState/ - User view states for each dataset. This stores UI info about how the view was configured
  - ----------------quantification.json - The quantification loaded on UI top toolbar
  - ----------------roi.json - Colours assigned to ROIs on the UI
  - ----------------selection.json - The users current selection of PMCs and/or pixels on UI
  - ----------------analysisLayout.json - What widgets go where, top row/bottom row
  - -----------------<panel-type>-<location>.json - States of various UI panels and where they are
  - -----------------  See: GetViewStatePath()
  - -----------------  Workspaces/
  - --------------------<workspace-name>.json - View state files (like up one directory) flattened to a file and given a workspace name. Note the file also contains the workspace name, the file name may have been modified for saving, eg removal of /
  - --------------------  See: GetWorkspacePath()
  - --------------------  WorkspaceCollections/
  - --------------------<collection-name>.json
  - --------------------  See: GetCollectionPath()
  - ----shared/ - All shared objects go here. Kind of like if they belong to a user called "shared". NOTE: User diffraction/roughness files are shared by default!
*/
const RootUserContent = "UserContent"
const elementSetFile = "ElementSets.json"
const rgbMixFile = "RGBMixes.json"
const roiFile = "ROI.json"
const tagFile = "Tags.json"

// Multi-quant z-stack file name
const MultiQuantZStackFile = "multi-quant-z-stack.json"

const annotationFile = "SpectrumAnnotation.json"
const quantificationSubPath = "Quantifications"

// Retrieves files for a user and dataset ID. If fileName is blank, it only returns the directory path
func GetUserQuantPath(userID string, datasetID string, fileName string) string {
	if len(fileName) > 0 {
		return path.Join(RootUserContent, userID, datasetID, quantificationSubPath, fileName)
	}
	return path.Join(RootUserContent, userID, datasetID, quantificationSubPath)
}

const quantLastOutputSubPath = "LastPiquantOutput"

// File name of last piquant output (used with fit command). Extension added as needed
const QuantLastOutputFileName = "output_data"

// File name of last piquant output log file (used with fit command)
const QuantLastOutputLogName = "output.log"

// Retrieve path for last outputs, eg last run fit command (command is actually "quant"), sits in here with its log file
func GetUserLastPiquantOutputPath(userID string, datasetID string, piquantCommand string, fileName string) string {
	if len(fileName) > 0 {
		return path.Join(RootUserContent, userID, datasetID, quantLastOutputSubPath, piquantCommand, fileName)
	}
	return path.Join(RootUserContent, userID, datasetID, quantLastOutputSubPath, piquantCommand)
}

const viewStatePath = "ViewState"

// TODO: Move files directly in ViewState/ into their own directory, eg Last/ because
// currently we have to check what we're deleting if resetting view state for example

// Sub-dir containing all workspaces. These are saved copies of view states
const ViewStateSavedSubpath = "Workspaces"

// Sub-dir containing all workspace collections. These are flat files containing all workspaces they were created from
const ViewStateCollectionsSubpath = "WorkspaceCollections"

// Gets user content file path by user id and file name
func GetUserContentPath(userID string, fileName string) string {
	return path.Join(RootUserContent, userID, fileName)
}

// Gets user content file path for a given dataset id. Also requires user id, and the file name
func GetUserContentDatasetPath(userID string, datasetID string, fileName string) string {
	return path.Join(RootUserContent, userID, datasetID, fileName)
}

// Name of user manually entered diffraction peaks file. NOTE: this file only exists as a shared file!
const DiffractionPeakManualFileName = "manual-diffraction-peaks.json"

// Name of file containing status of diffraction peaks - the diffraction DB is generated when dataset is created
// but users can view a peak and mark it with a status, eg to delete it because it's not a real diffraction peak
// OTE: this file only exists as a shared file!
const DiffractionPeakStatusFileName = "diffraction-peak-statuses.json"

// Same as GetUserContentDatasetPath() but for shared user
func GetSharedContentDatasetPath(datasetID string, fileName string) string {
	return path.Join(RootUserContent, pixlUser.ShareUserID, datasetID, fileName)
}

// Same as GetUserQuantPath() but for shared user
func GetSharedQuantPath(datasetID string, fileName string) string {
	return GetUserQuantPath(pixlUser.ShareUserID, datasetID, fileName)
}

/*
Root directory containing all user activity stored, to track clicks and user flows for research purposes
  - Activity/
  - -----------<datestamp>/<GUID>.json - User activity files (things captured by middleware logger)
*/
const RootUserActivity = "Activity"

////////////////////////////////////////////////////////////////////////////////////
// Job Bucket
////////////////////////////////////////////////////////////////////////////////////

/*
This contains temporary files generated when running a long-running job (eg PIQUANT).
Contains parameters to the job, status files, log files from the job, intermediate calculation files
These are in separate directories to aid listing, so instead of returning 100s of files per job
you may only want a list of job statuses, where you'd only get 1 file per job
  - JobData/
  - ----<dataset-id>/
  - --------<job-id>/
  - ------------node*.pmcs - PMC list for a given node running the job
  - ------------params.json - Job parameters as specified when created
  - ------------output/
  - ----------------node*.pmcs_result.csv - CSV generated by a single node, intermediate outpu
  - ----------------combined.csv - The final output generated by combining all the node*.pmcs_result.csv files
  - ------------piquant-logs/
  - ----------------node*.pmcs_piquant.log - PIQUANT log file for a given node
  - ----------------node*.pmcs_stdout.log - stdout for running PIQUANT on a given node
*/
const RootJobData = "JobData"

// Piquant logs sub-directory
const PiquantLogSubdir = "piquant-logs"

// Retrieves the path of a given file for dataset, job id and file name. NOTE: if job ID is blank, it's omitted
// from the path, and same for file name
func GetJobDataPath(datasetID string, jobID string, fileName string) string {
	if len(jobID) > 0 {
		if len(fileName) > 0 {
			return path.Join(RootJobData, datasetID, jobID, fileName)
		}
		return path.Join(RootJobData, datasetID, jobID)
	}
	return path.Join(RootJobData, datasetID)
}

/*
Root directory for all job statuses. These are stored separately to JobData so we can easily list all jobs and
query their statuses
  - JobStatus/
  - ----<dataset-id>/<job-id>-status.json
*/
const RootJobStatus = "JobStatus"

// Job status file name suffix. Appended to the job ID
const JobStatusSuffix = "-status.json"

// Retrieves the path of a job status file for given dataset id and job id. If job id is blank, this just
// returns the root of all job statuses for the given datset id
func GetJobStatusPath(datasetID string, jobID string) string {
	if len(jobID) <= 0 {
		return path.Join(RootJobStatus, datasetID)
	}
	return path.Join(RootJobStatus, datasetID, jobID+JobStatusSuffix)
}

/*
Root directory for all job summaries. This is stored separately to JobData so we can easily list all jobs
and get their metadata (summary) files
  - JobSummaries/
  - ----<dataset-id>-jobs.json - Summary files describing all jobs for a dataset
*/
const RootJobSummaries = "JobSummaries"

// Job summary file name suffix. Appended to dataset ID
const JobSummarySuffix = "-jobs.json"

// Gets the job summary path for a given dataset ID
func GetJobSummaryPath(datasetID string) string {
	return path.Join(RootJobSummaries, datasetID+JobSummarySuffix)
}

////////////////////////////////////////////////////////////////////////////////////
// Artifacts Manual Upload Data Source Bucket
////////////////////////////////////////////////////////////////////////////////////

/*
Root directory for all dataset add-ons. These are custom files that can be uploaded for a datset to set its
title, and which the "default" image is, etc.
  - dataset-addons/
  - ----<dataset-id>/
  - --------custom-meta.json - Custom metadata for this dataset, usually to set dataset title, but can also contain matched image scale/bias or other fields
  - ------------UNALINED/
  - ----------------image, *.png or *.jpg
  - ------------MATCHED/
  - ----------------image, *.png, *.jpg or *.tif (if TIF it's considered an RGBU multi-spectral image)
  - ------------RGBU/
  - ----------------images, *.tif - NOTE: Went unused, these are now all stored as MATCHED images
*/
const DatasetCustomRoot = "dataset-addons"

// File name for dataset custom meta file containing the title and other settings
const DatasetCustomMetaFileName = "custom-meta.json"

// Get the custom meta file path for a given dataset ID
func GetCustomMetaPath(datasetID string) string {
	return path.Join(DatasetCustomRoot, datasetID, DatasetCustomMetaFileName)
}

// Get the custom image path for a given dataset ID. Note imageType must be one of UNALIGNED, MATCHED or RGBU
func GetCustomImagePath(datasetID string, imgType string, fileName string) string {
	// NOTE: We assume imgType is valid!
	s3Path := path.Join(DatasetCustomRoot, datasetID, strings.ToUpper(imgType))
	if len(fileName) > 0 {
		s3Path = path.Join(s3Path, fileName)
	}
	return s3Path
}

/*
Root directory to store uploaded dataset "raw" artifacts. These are then read by dataset importer
to create a dataset in the dataset bucket
  - Uploaded/
  - ----<dataset-id>/
  - --------Files for that dataset importer type. For example, with breadboards we expect:
  - --------import.json <-- Describes what's what
  - --------spectra.zip <-- Spectra .msa files zipped up
  - --------context_image_1.jpg <-- 1 or more context images
*/
const DatasetUploadRoot = "UploadedDatasets"

// Gets the path to a file in the dataset upload area, for a given dataset id and file name
func GetDatasetUploadPath(datasetID string, fileName string) string {
	return path.Join(DatasetUploadRoot, datasetID, fileName)
}

////////////////////////////////////////////////////////////////////////////////////
// Artifacts Built Bucket - where we go to download built PIQUANT, etc
////////////////////////////////////////////////////////////////////////////////////

/*
PIQUANT binaries root file - this kind of went unused and is likely not working because
our build process doesn't write to the bucket any more
  - piquant/
  - ----piquant-linux-*.zip - Built PIQUANT executables (zipped)
*/
const PiquantDownloadPath = "piquant"

////////////////////////////////////////////////////////////////////////////////////
// Some specific helper functions for better searchability/grouping
////////////////////////////////////////////////////////////////////////////////////

// Getting element set file path for a user
func GetElementSetPath(userID string) string {
	return GetUserContentPath(userID, elementSetFile)
}

// Getting RGB mix file path for a user
func GetRGBMixPath(userID string) string {
	return GetUserContentPath(userID, rgbMixFile)
}

// Getting ROI file path for a user and dataset
func GetROIPath(userID string, datasetID string) string {
	return GetUserContentDatasetPath(userID, datasetID, roiFile)
}

// Getting tag file path for a user
func GetTagPath(userID string) string {
	return GetUserContentPath(userID, tagFile)
}

// Getting multi-quant z-stack file path for a user and dataset
func GetMultiQuantZStackPath(userID string, datasetID string) string {
	return GetUserContentDatasetPath(userID, datasetID, MultiQuantZStackFile)
}

// Getting spectrum annotations file path for a user and dataset
func GetAnnotationsPath(userID string, datasetID string) string {
	return GetUserContentDatasetPath(userID, datasetID, annotationFile)
}

// Getting view state file path for a user, dataset and file name. Note if file name is blank, this just returns the directory
func GetViewStatePath(userID string, datasetID string, fileName string) string {
	if len(fileName) <= 0 {
		// Just return the root of this
		return path.Join(RootUserContent, userID, datasetID, viewStatePath)
	}
	return path.Join(RootUserContent, userID, datasetID, viewStatePath, fileName+".json")
}

// Getting workspace file path for a user, dataset and workspace ID. Note if id is blank, this just returns the directory
// Validates ids to make sure they are valid (because the id is actually part of the file name)
func GetWorkspacePath(userID string, datasetID string, id string) string {
	if len(id) <= 0 {
		// Just return the root of this
		return path.Join(RootUserContent, userID, datasetID, viewStatePath, ViewStateSavedSubpath)
	}
	// ensure it's a valid file name
	id = fileaccess.MakeValidObjectName(id, true)
	return path.Join(RootUserContent, userID, datasetID, viewStatePath, ViewStateSavedSubpath, id+".json")
}

// Getting collection file path for a user, dataset and workspace ID. Note if id is blank, this just returns the directory
// Validates ids to make sure they are valid (because the id is actually part of the file name)
func GetCollectionPath(userID string, datasetID string, id string) string {
	if len(id) <= 0 {
		// Just return the root of this
		return path.Join(RootUserContent, userID, datasetID, viewStatePath, ViewStateCollectionsSubpath)
	}
	// ensure it's a valid file name
	id = fileaccess.MakeValidObjectName(id, true)
	return path.Join(RootUserContent, userID, datasetID, viewStatePath, ViewStateCollectionsSubpath, id+".json")
}

////////////////////////////////////////////////////////////////////////////////////
// Helpers for forming certain file names
////////////////////////////////////////////////////////////////////////////////////

// QuantSummaryFilePrefix - summary files are summary-<jobid>.json
const QuantSummaryFilePrefix = "summary-"

// MakeQuantSummaryFileName - Given a quant ID, generates the file name: summary-<jobid>.json (use this for searchability/consistency)
func MakeQuantSummaryFileName(quantID string) string {
	return QuantSummaryFilePrefix + quantID + ".json"
}

// QuantFileSuffix - quant files are <jobid>.bin
const QuantFileSuffix = ".bin"

func MakeQuantDataFileName(quantID string) string {
	return quantID + QuantFileSuffix
}

// CSVFileSuffix - CSV files are <jobid>.csv
const CSVFileSuffix = ".csv"

func MakeQuantCSVFileName(quantID string) string {
	return quantID + CSVFileSuffix
}

// QuantLogsSubDirSuffix - this goes after job ID to form a directory name that stores the quant logs
const QuantLogsSubDirSuffix = "-logs"

func MakeQuantLogDirName(quantID string) string {
	return quantID + QuantLogsSubDirSuffix
}
